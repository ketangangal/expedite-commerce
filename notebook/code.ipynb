{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from litellm import completion\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Model Config\n",
    "load_dotenv()\n",
    "config = {\n",
    "    \"model\": f\"azure/{os.getenv('AZURE_DEPLOYMENT')}\",\n",
    "    \"api_key\": os.getenv(\"AZURE_API_KEY\"),\n",
    "    \"base_url\": os.getenv(\"AZURE_ENDPOINT\"),\n",
    "    \"api_version\": os.getenv(\"AZURE_API_VERSION\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-AyjMhOA0ZecwLt4FQdXv0OBPXxSt1',\n",
       " 'created': 1739037427,\n",
       " 'model': 'gpt-4o-2024-08-06',\n",
       " 'object': 'chat.completion',\n",
       " 'system_fingerprint': 'fp_f3927aa00d',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'message': {'content': 'Good morning! How can I assist you today?',\n",
       "    'role': 'assistant',\n",
       "    'tool_calls': None,\n",
       "    'function_call': None,\n",
       "    'refusal': None}}],\n",
       " 'usage': {'completion_tokens': 10,\n",
       "  'prompt_tokens': 9,\n",
       "  'total_tokens': 19,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'service_tier': None,\n",
       " 'prompt_filter_results': [{'prompt_index': 0,\n",
       "   'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'},\n",
       "    'jailbreak': {'filtered': False, 'detected': False},\n",
       "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
       "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
       "    'violence': {'filtered': False, 'severity': 'safe'}}}]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = completion(\n",
    "    **config,\n",
    "    messages = [{\"role\": \"user\", \"content\": \"good morning\"}]\n",
    ")\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_request = [{\n",
    "    \"feedback_id\": \"12345\",\n",
    "    \"customer_name\": \"John Doe\",\n",
    "    \"feedback_text\": \"The product is great, but the delivery was delayed.\",\n",
    "    \"timestamp\": \"2025-01-10T10:30:00Z\",\n",
    "    \"instructions\": \"Focus on identifying the sentiment and summarizing actionable insights.\"\n",
    "},\n",
    "{\n",
    "    \"feedback_id\": \"12345\",\n",
    "    \"customer_name\": \"John Doe\",\n",
    "    \"feedback_text\": \"hello how are you ??\",\n",
    "    \"timestamp\": \"2025-01-10T10:30:00Z\",\n",
    "    \"instructions\": \"\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Schema Genertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_function_schema(base_model: BaseModel):\n",
    "    schema = base_model.model_json_schema()\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": schema.get(\"title\", base_model.__name__),\n",
    "            \"description\": schema.get(\"description\", \"None\"),\n",
    "            \"parameters\": {\n",
    "                \"type\": schema.get(\"type\", \"object\"),\n",
    "                \"properties\": schema.get(\"properties\")\n",
    "            }\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubAgent(BaseModel):\n",
    "    \"\"\"useful when to answer question based on feedback and Instructions.\n",
    "    It can help with SentimentAnalysis, TopicCategorization, KeywordContextualization, Summarization\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'SubAgent',\n",
       "  'description': 'useful when to answer question based on feedback and Instructions.\\nIt can help with SentimentAnalysis, TopicCategorization, KeywordContextualization, Summarization',\n",
       "  'parameters': {'type': 'object', 'properties': {}}}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = generate_function_schema(base_model=SubAgent)\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: SubAgent for Tool calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Tool\n",
    "- Perform sentiment scoring (positive, negative, neutral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysisTool(BaseModel):\n",
    "    query: str\n",
    "\n",
    "\n",
    "def sentiment_analysis_tool(query: str, config: dict):\n",
    "    # Prompt\n",
    "    prompt = \"\"\"Analyze the sentiment of the following user feedback and provide a JSON response with sentiment scores for positive, negative, and neutral categories. \n",
    "    \n",
    "    NOTE: Ensure the sum of all values equals 1. Do not provide any explanation.  \n",
    "\n",
    "    Output format:  \n",
    "    ```json  \n",
    "    {{ \"positive\": <score>, \"negative\": <score>, \"neutral\": <score>}}\n",
    "    ```\n",
    "\n",
    "    Feedback: {user_feedback}\n",
    "    \"\"\".format(user_feedback=query)\n",
    "\n",
    "    response = completion(\n",
    "        **config, \n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    # Parsing and Loading\n",
    "    output = response.choices[0].message.content.strip(\"```json\").strip('```')[1:-1]\n",
    "    return json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation:  {'positive': 0.4, 'negative': 0.4, 'neutral': 0.2}\n"
     ]
    }
   ],
   "source": [
    "observation = sentiment_analysis_tool(\n",
    "    query=\"The product is great, but the delivery was delayed\", \n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"Observation: \", observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Categorization Tool\n",
    "- Categorize feedback into predefined topics (e.g., Product Quality, Delivery, Support).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicCategorizationTool(BaseModel):\n",
    "    query: str\n",
    "\n",
    "def topic_categorization_tool(query: str, config: dict):\n",
    "    # Prompt\n",
    "    prompt = \"\"\"Categorize the following user feedback into one of the predefined topics: `Product Quality`, `Delivery`, `Support`.\n",
    "    \n",
    "    NOTE: Select only one category and assign it a confidence score between 0 and 1. \n",
    "    Do not provide any explanation.  \n",
    "\n",
    "    Output format:  \n",
    "    ```json  \n",
    "    {{ \"category\": <Selected Category>, \"score\": <confidence_score>}}\n",
    "    ```\"  \n",
    "\n",
    "    Feedback: {product_info}\n",
    "    \"\"\".format(product_info=query)\n",
    "\n",
    "    response = completion(\n",
    "        **config, \n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    # Parsing and Loading\n",
    "    output = response.choices[0].message.content.strip(\"```json\").strip('```')[1:-1]\n",
    "    return json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation:  {'category': 'Delivery', 'score': 0.8}\n"
     ]
    }
   ],
   "source": [
    "observation = topic_categorization_tool(\n",
    "    query=\"The product is great, but the delivery was delayed\", \n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"Observation: \", observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Contextualization Tool\n",
    "- Extract context-aware keywords with relevance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordContextualizationTool(BaseModel):\n",
    "    query: str\n",
    "\n",
    "\n",
    "def keyword_contextualization_tool(query: str, config: dict):\n",
    "    # Prompt\n",
    "    prompt = \"\"\"Extract context-aware keywords from the following user feedback along with their relevance scores. \n",
    "    \n",
    "    NOTE: Provide a JSON response where each keyword is mapped to a relevance score between 0 and 1. \n",
    "    Do not provide any explanation. \n",
    "\n",
    "    Output format:  \n",
    "    ```json  \n",
    "    {{ \"keywords\": {{ \"<keyword1>\": <score>, \"<keyword2>\": <score>, \"<keyword3>\": <score> }}}}\n",
    "    ```\"  \n",
    "\n",
    "    Feedback: {user_feedback}\n",
    "    \"\"\".format(user_feedback=query)\n",
    "\n",
    "    response = completion(\n",
    "        **config, \n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    # Parsing and Loading\n",
    "    output = response.choices[0].message.content.strip(\"```json\").strip('```')[1:-1]\n",
    "    return json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation:  {'keywords': {'product': 0.3, 'great': 0.2, 'delivery': 0.4, 'delayed': 0.6}}\n"
     ]
    }
   ],
   "source": [
    "observation = keyword_contextualization_tool(\n",
    "    query=\"The product is great, but the delivery was delayed\", \n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"Observation: \", observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization Tool\n",
    "- Generate concise summaries and actionable recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationTool(BaseModel):\n",
    "    query: str\n",
    "\n",
    "\n",
    "def summarization_tool(query: str, config: dict):\n",
    "    # Prompt\n",
    "    prompt = \"\"\"Summarize the following user feedback concisely and provide actionable recommendations. \n",
    "    \n",
    "    NOTE: Ensure the summary captures the core message, and the recommendations are practical and relevant. \n",
    "    Do not provide any explanation.  \n",
    "\n",
    "    Output format:  \n",
    "    ```json  \n",
    "    {{  \n",
    "    \"summary\": \"<short concise summary>\",  \n",
    "    \"recommendations\": [\"<short actionable recommendation 1>\", \"<short actionable recommendation 2>\"]  \n",
    "    }}  \n",
    "    ```\"  \n",
    "\n",
    "    Feedback: {user_feedback}\n",
    "    \"\"\".format(user_feedback=query)\n",
    "\n",
    "    response = completion(\n",
    "        **config, \n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    # Parsing and Loading\n",
    "    output = response.choices[0].message.content.strip(\"```json\").strip('```')[1:-1]\n",
    "    return json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation:  {'summary': 'Users are satisfied with the product but are experiencing delivery delays.', 'recommendations': ['Improve delivery process to ensure timely shipments', 'Communicate proactively with customers about delivery status']}\n"
     ]
    }
   ],
   "source": [
    "observation = summarization_tool(\n",
    "    query=\"The product is great, but the delivery was delayed\", \n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"Observation: \", observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SubAgent Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [SummarizationTool, SentimentAnalysisTool, KeywordContextualizationTool, TopicCategorizationTool]\n",
    "sub_agent_tools = [generate_function_schema(base_model=tool) for tool in tools]\n",
    "\n",
    "def sub_agent(input_request: dict, tools: list, config: dict):\n",
    "    print(f\"Initiate Sub agent : ...\")\n",
    "    prompt = \"\"\"You are a specialized sub-agent equipped with four tools:  \n",
    "\n",
    "        1. SentimentAnalysisTool – Analyzes sentiment (positive, negative, neutral) with confidence scores.  \n",
    "        2. TopicCategorizationTool – Categorizes feedback into predefined topics (`Product Quality`, `Delivery`, `Support`).  \n",
    "        3. KeywordContextualizationTool – Extracts context-aware keywords with relevance scores.  \n",
    "        4. SummarizationTool – Generates concise summaries and actionable recommendations.  \n",
    "\n",
    "    Your task is to answer the user based on feedback and instruction given.   \n",
    "        - If an instruction is provided, select only the relevant tools accordingly.  \n",
    "        - If no instruction is provided, use **all four tools** to extract comprehensive insights.  \n",
    "        - You can use multiple tools at once when necessary.  \n",
    "\n",
    "    #### **User Input:**  \n",
    "        Feedback_text : {feedback_text}\n",
    "        Instruction : {instructions}\n",
    "    \"\"\".format(\n",
    "        feedback_text=input_request.get(\"feedback_text\", \"N/A\"),\n",
    "        instructions=input_request.get(\"instructions\", \"N/A\")\n",
    "    )\n",
    "\n",
    "    # LLm call\n",
    "    print(f\"Initiate Sub agent LLM call: ...\")\n",
    "    response = completion(\n",
    "        **config, \n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "        tools=tools\n",
    "    )\n",
    "    \n",
    "    print(f\"Initiate Sub agent LLM call: {response}\")\n",
    "    \n",
    "    # sub agent call\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        result = tool_executor(\n",
    "            input_request=input_request, \n",
    "            tool_calls=response.choices[0].message.tool_calls\n",
    "        )\n",
    "        return result[\"agent_response\"]\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feedback_id': '12345',\n",
       " 'customer_name': 'John Doe',\n",
       " 'feedback_text': 'The product is great, but the delivery was delayed.',\n",
       " 'timestamp': '2025-01-10T10:30:00Z',\n",
       " 'instructions': 'Focus on identifying the sentiment and summarizing actionable insights.'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_request[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Name: SentimentAnalysisTool\n",
      "Action Input: {'query': 'The product is great, but the delivery was delayed.'}\n",
      "Action Result {'positive': 0.4, 'negative': 0.4, 'neutral': 0.2}\n",
      "Action Name: SummarizationTool\n",
      "Action Input: {'query': 'The product is great, but the delivery was delayed.'}\n",
      "Action Result {'summary': 'Product quality is excellent, but delivery is slow.', 'recommendations': ['Improve delivery timelines', 'Communicate delay status promptly to customers']}\n"
     ]
    }
   ],
   "source": [
    "response = sub_agent(\n",
    "    input_request=input_request[0], tools=sub_agent_tools, config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentimentanalysis': {'positive': 0.4, 'negative': 0.4, 'neutral': 0.2}},\n",
       " {'summarization': {'summary': 'Product quality is excellent, but delivery is slow.',\n",
       "   'recommendations': ['Improve delivery timelines',\n",
       "    'Communicate delay status promptly to customers']}}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Executor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolExecutor:\n",
    "    def __init__(self, tools: list, config: dict) -> None:\n",
    "        # common tool executor\n",
    "        self.config = config\n",
    "        self.tools_by_name = {\n",
    "            schema.get(\"title\", \"N/A\"): tool for schema, tool in tools\n",
    "        }\n",
    "\n",
    "        # sub agent tools\n",
    "        sub_agent_tools = [SummarizationTool, SentimentAnalysisTool, KeywordContextualizationTool, TopicCategorizationTool]\n",
    "        self.sub_agent_tools = [generate_function_schema(base_model=tool) for tool in sub_agent_tools]\n",
    "\n",
    "    def __call__(self, input_request: dict, tool_calls: list):\n",
    "        output = []\n",
    "        for tool_call in tool_calls:\n",
    "            tool_name = tool_call.function.name\n",
    "            tool_args = json.loads(tool_call.function.arguments)\n",
    "            print(f\"Action Name: {tool_name}\\nAction Input: {tool_args}\")\n",
    "            \n",
    "            if tool_name != \"SubAgent\":\n",
    "                tool_result = self.tools_by_name[tool_name](**tool_args, config=config)\n",
    "            else:\n",
    "                tool_result = self.tools_by_name[tool_name](\n",
    "                    input_request=input_request,\n",
    "                    tools = self.sub_agent_tools,\n",
    "                    config=config\n",
    "                    )\n",
    "                \n",
    "            print(f\"Action Result: {tool_result}\")\n",
    "            output.append({f'{tool_name.lower().replace(\"tool\",\"\")}': tool_result})\n",
    "\n",
    "        input_request[\"agent_response\"] = output\n",
    "        return input_request\n",
    "\n",
    "executor_tools = [\n",
    "    (SubAgent.model_json_schema(), sub_agent), \n",
    "    (SentimentAnalysisTool.model_json_schema(), sentiment_analysis_tool),\n",
    "    (TopicCategorizationTool.model_json_schema(), topic_categorization_tool),\n",
    "    (KeywordContextualizationTool.model_json_schema(), keyword_contextualization_tool),\n",
    "    (SummarizationTool.model_json_schema(), summarization_tool)\n",
    "]\n",
    "\n",
    "tool_executor = ToolExecutor(tools=executor_tools, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Master Agent for Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_tools = [generate_function_schema(base_model=SubAgent)]\n",
    "\n",
    "def master_agent(input_request: dict, tools: list, config: dict):\n",
    "    print(f\"Initiate User Request : {input_request}\")\n",
    "    # This is master agent Prompt\n",
    "    prompt = \"\"\"You are a master agent responsible for handling general user interactions, greetings, and generic inquiries. \n",
    "    However, when the user provides instructions or mentions product-related details, you must delegate the task to a specialized sub-agent.  \n",
    "\n",
    "    NOTE:\n",
    "    - If the input is a general inquiry, greeting, or small talk, respond directly.  \n",
    "    - If the user input contains instructions or product-related details, do not respond directly. \n",
    "      Instead, forward the request to the sub-agent using the exact instruction and feedback text provided by the user. \n",
    "    - Ensure responses are clear and structured.\n",
    "\n",
    "    This keeps the master agent focused on general conversations while offloading specific tasks to the sub-agent.\n",
    "\n",
    "    USER_INPUTS:\n",
    "        Feedback_text: {feedback_text}\n",
    "        Instructions: {instructions}\n",
    "    \"\"\".format(\n",
    "        feedback_text=input_request.get(\"feedback_text\", \"N/A\"),\n",
    "        instructions=input_request.get(\"instructions\", \"N/A\")\n",
    "    )\n",
    "\n",
    "    print(\"Triggered Master Agent: .....\")\n",
    "    # LLm call\n",
    "    response = completion(\n",
    "        **config, \n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "    print(f\"Master Agent Response : {response.json()}\")\n",
    "\n",
    "    # sub agent call\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        result = tool_executor(\n",
    "            input_request=input_request, \n",
    "            tool_calls=response.choices[0].message.tool_calls\n",
    "        )\n",
    "        print(f\"Master Agent Final Answer: {result}\")\n",
    "        return result\n",
    "    input_request[\"agent_response\"] = response.choices[0].message.content\n",
    "\n",
    "    print(f\"Master Agent Final Answer: {input_request}\")\n",
    "    return input_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate User Request : {'feedback_id': '12345', 'customer_name': 'John Doe', 'feedback_text': 'hello how are you ??', 'timestamp': '2025-01-10T10:30:00Z', 'instructions': '', 'agent_response': \"Hello! I'm here to assist you. I'm doing well, thank you for asking. How can I help you today?\"}\n",
      "Triggered Master Agent: .....\n",
      "Master Agent Response : {'id': 'chatcmpl-AyjXcCiZXna3NGNHGVPNSPqgWIpiA', 'created': 1739038104, 'model': 'gpt-4o-2024-08-06', 'object': 'chat.completion', 'system_fingerprint': 'fp_f3927aa00d', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': \"Hello! I'm doing well, thank you for asking. How can I assist you today?\", 'role': 'assistant', 'tool_calls': None, 'function_call': None, 'refusal': None}}], 'usage': {'completion_tokens': 19, 'prompt_tokens': 221, 'total_tokens': 240, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]}\n",
      "Master Agent Final Answer: {'feedback_id': '12345', 'customer_name': 'John Doe', 'feedback_text': 'hello how are you ??', 'timestamp': '2025-01-10T10:30:00Z', 'instructions': '', 'agent_response': \"Hello! I'm doing well, thank you for asking. How can I assist you today?\"}\n"
     ]
    }
   ],
   "source": [
    "observation = master_agent(\n",
    "    input_request=input_request[1], \n",
    "    config=config,\n",
    "    tools=master_tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feedback_id': '12345',\n",
       " 'customer_name': 'John Doe',\n",
       " 'feedback_text': 'hello how are you ??',\n",
       " 'timestamp': '2025-01-10T10:30:00Z',\n",
       " 'instructions': '',\n",
       " 'agent_response': \"Hello! I'm doing well, thank you for asking. How can I assist you today?\"}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from boto3 import client\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "bedrock = client(\n",
    "    \"bedrock-runtime\", \n",
    "    region_name=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock.apply_guardrail(\n",
    "    guardrailIdentifier=\"8j0uvjqavz1m\",\n",
    "    guardrailVersion=\"1\",\n",
    "    source=\"INPUT\",\n",
    "    content=[{\"text\": {\"text\": json.dumps({\"test\": \"hello how are you\"})}}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f4c7f45b-f6b3-467c-a3d8-a98ababd41c6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sun, 09 Feb 2025 07:04:36 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '615',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'f4c7f45b-f6b3-467c-a3d8-a98ababd41c6'},\n",
       "  'RetryAttempts': 0},\n",
       " 'usage': {'topicPolicyUnits': 0,\n",
       "  'contentPolicyUnits': 1,\n",
       "  'wordPolicyUnits': 0,\n",
       "  'sensitiveInformationPolicyUnits': 0,\n",
       "  'sensitiveInformationPolicyFreeUnits': 0,\n",
       "  'contextualGroundingPolicyUnits': 0},\n",
       " 'action': 'NONE',\n",
       " 'outputs': [],\n",
       " 'assessments': [{'invocationMetrics': {'guardrailProcessingLatency': 206,\n",
       "    'usage': {'topicPolicyUnits': 0,\n",
       "     'contentPolicyUnits': 1,\n",
       "     'wordPolicyUnits': 0,\n",
       "     'sensitiveInformationPolicyUnits': 0,\n",
       "     'sensitiveInformationPolicyFreeUnits': 0,\n",
       "     'contextualGroundingPolicyUnits': 0},\n",
       "    'guardrailCoverage': {'textCharacters': {'guarded': 29, 'total': 29}}}}],\n",
       " 'guardrailCoverage': {'textCharacters': {'guarded': 29, 'total': 29}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '460b7ac9-9188-4205-a110-4b55161b226a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sun, 09 Feb 2025 07:00:36 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '1005',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '460b7ac9-9188-4205-a110-4b55161b226a'},\n",
       "  'RetryAttempts': 0},\n",
       " 'usage': {'topicPolicyUnits': 0,\n",
       "  'contentPolicyUnits': 1,\n",
       "  'wordPolicyUnits': 0,\n",
       "  'sensitiveInformationPolicyUnits': 0,\n",
       "  'sensitiveInformationPolicyFreeUnits': 0,\n",
       "  'contextualGroundingPolicyUnits': 0},\n",
       " 'action': 'GUARDRAIL_INTERVENED',\n",
       " 'outputs': [{'text': 'Sorry, the model cannot answer this question.'}],\n",
       " 'assessments': [{'contentPolicy': {'filters': [{'type': 'VIOLENCE',\n",
       "      'confidence': 'MEDIUM',\n",
       "      'filterStrength': 'HIGH',\n",
       "      'action': 'BLOCKED'},\n",
       "     {'type': 'HATE',\n",
       "      'confidence': 'MEDIUM',\n",
       "      'filterStrength': 'HIGH',\n",
       "      'action': 'BLOCKED'}]},\n",
       "   'invocationMetrics': {'guardrailProcessingLatency': 204,\n",
       "    'usage': {'topicPolicyUnits': 0,\n",
       "     'contentPolicyUnits': 1,\n",
       "     'wordPolicyUnits': 0,\n",
       "     'sensitiveInformationPolicyUnits': 0,\n",
       "     'sensitiveInformationPolicyFreeUnits': 0,\n",
       "     'contextualGroundingPolicyUnits': 0},\n",
       "    'guardrailCoverage': {'textCharacters': {'guarded': 21, 'total': 21}}}}],\n",
       " 'guardrailCoverage': {'textCharacters': {'guarded': 21, 'total': 21}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = bedrock.apply_guardrail(\n",
    "    guardrailIdentifier=\"8j0uvjqavz1m\",\n",
    "    guardrailVersion=\"1\",\n",
    "    source=\"INPUT\",\n",
    "    content=[{\"text\": {\"text\": json.dumps({\"test\": \"I want to kill you\"})}}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_guardrail_response(response: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Parse the Bedrock guardrail response and return a structured explanation\n",
    "    of why the content was blocked.\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"status\": response.get(\"action\", \"UNKNOWN\"),\n",
    "        \"is_blocked\": False,\n",
    "        \"reasons\": [],\n",
    "        \"details\": {}\n",
    "    }\n",
    "    \n",
    "    if response[\"action\"] == \"GUARDRAIL_INTERVENED\":\n",
    "        result[\"is_blocked\"] = True\n",
    "        \n",
    "        if \"assessments\" in response:\n",
    "            for assessment in response[\"assessments\"]:\n",
    "                if \"contentPolicy\" in assessment:\n",
    "                    filters = assessment[\"contentPolicy\"].get(\"filters\", [])\n",
    "                    \n",
    "                    for filter_info in filters:\n",
    "                        violation = {\n",
    "                            \"type\": filter_info.get(\"type\"),\n",
    "                            \"confidence\": filter_info.get(\"confidence\"),\n",
    "                            \"strength\": filter_info.get(\"filterStrength\"),\n",
    "                            \"action\": filter_info.get(\"action\")\n",
    "                        }\n",
    "                        result[\"reasons\"].append(violation)\n",
    "        \n",
    "        if \"guardrailCoverage\" in response:\n",
    "            result[\"details\"][\"coverage\"] = response[\"guardrailCoverage\"]\n",
    "            \n",
    "        if \"usage\" in response:\n",
    "            result[\"details\"][\"usage\"] = response[\"usage\"]\n",
    "    \n",
    "    return result\n",
    "\n",
    "response = parse_guardrail_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'NONE', 'is_blocked': False, 'reasons': [], 'details': {}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Chaching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_payload = {'feedback_id': '12345',\n",
    " 'customer_name': 'John Doe',\n",
    " 'feedback_text': 'hello how are you ??',\n",
    " 'timestamp': '2025-01-10T10:30:00Z',\n",
    " 'instructions': '',\n",
    " 'agent_response': [\"Hello! I'm doing well, thank you for asking. How can I assist you today?\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def store_feedback_cache(feedback_id, cache_key, cached_result):\n",
    "    TABLE_NAME = \"FeedbackCache\"\n",
    "\n",
    "    dynamodb = boto3.client(\"dynamodb\", region_name=\"us-east-1\")\n",
    "    \n",
    "    last_updated = datetime.now().isoformat()\n",
    "    \n",
    "    dynamodb.put_item(\n",
    "        TableName=TABLE_NAME,\n",
    "        Item={\n",
    "            \"feedback_id\": {\"S\": feedback_id},\n",
    "            \"cache_key\": {\"S\": cache_key},\n",
    "            \"cached_result\": {\"S\": json.dumps(cached_result)},\n",
    "            \"last_updated\": {\"S\": last_updated}\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "feedback_id = input_payload[\"feedback_id\"]\n",
    "text = input_payload[\"feedback_text\"] + \" \" + input_payload[\"instructions\"]\n",
    "cache_key = hashlib.sha256(text.encode()).hexdigest()\n",
    "cache_data = input_payload[\"agent_response\"]\n",
    "\n",
    "save_feedback_cache(\n",
    "    feedback_id=feedback_id,\n",
    "    cache_key=cache_key,\n",
    "    cached_result=cache_data\n",
    ")\n",
    "print(\"Cache stored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_feedback_cache(feedback_id: str, cache_key=None):\n",
    "    TABLE_NAME = \"FeedbackCache\"\n",
    "\n",
    "    dynamodb = boto3.client(\"dynamodb\", region_name=\"us-east-1\")\n",
    "    \n",
    "    if cache_key:\n",
    "        response = dynamodb.get_item(\n",
    "            TableName=TABLE_NAME,\n",
    "            Key={\n",
    "                \"feedback_id\": {\"S\": feedback_id},\n",
    "                \"cache_key\": {\"S\": cache_key}\n",
    "            }\n",
    "        )\n",
    "        if \"Item\" in response:\n",
    "            return {response[\"Item\"][\"cache_key\"][\"S\"]:json.loads(response[\"Item\"][\"cached_result\"][\"S\"])}  # Return cached result\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        response = dynamodb.query(\n",
    "            TableName=TABLE_NAME,\n",
    "            KeyConditionExpression=\"feedback_id = :fid\",\n",
    "            ExpressionAttributeValues={\":fid\": {\"S\": feedback_id}}\n",
    "        )\n",
    "        output = {item[\"cache_key\"][\"S\"]: json.loads(item[\"cached_result\"][\"S\"]) for item in response.get(\"Items\", [])}\n",
    "        if output:\n",
    "            return output\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ef93596d7b46e990272cdf8118dee91c8a33f6b42fe3c9da1a404ee1dbc173c6': [\"Hello! I'm doing well, thank you for asking. How can I assist you today?\"]}\n"
     ]
    }
   ],
   "source": [
    "print(get_feedback_cache(\"12345\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(get_feedback_cache(\"12346\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_id = input_payload[\"feedback_id\"]\n",
    "text = input_payload[\"feedback_text\"] + \" \" + input_payload[\"instructions\"]\n",
    "cache_key = hashlib.sha256(text.encode()).hexdigest()\n",
    "cache_data = input_payload[\"agent_response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ef93596d7b46e990272cdf8118dee91c8a33f6b42fe3c9da1a404ee1dbc173c6': [\"Hello! I'm doing well, thank you for asking. How can I assist you today?\"]}\n"
     ]
    }
   ],
   "source": [
    "print(get_feedback_cache(feedback_id, cache_key))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(get_feedback_cache(\"23223\", cache_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "import watchtower\n",
    "\n",
    "client_logs = boto3.client(\n",
    "    \"logs\", \n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "# Initialize CloudWatch Logs client\n",
    "LOG_GROUP = \"Expedite-Commerce-Feedback-Analysis\"  \n",
    "LOG_STREAM = \"Expedite-Commerce-Feedback-Analysis-Stream\"\n",
    " \n",
    "handler = watchtower.CloudWatchLogHandler(\n",
    "    log_group=LOG_GROUP, \n",
    "    stream_name=LOG_STREAM,\n",
    "    boto3_client=client_logs\n",
    "    )\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s : %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Create the logging instance\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Hello, world! from local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TABLE_NAME = \"FeedbackCache\"\n",
    "\n",
    "dynamodb = boto3.client(\"dynamodb\", region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting item:  {'last_updated': {'S': '2025-02-09T19:02:54.743616'}, 'feedback_id': {'S': '15345'}, 'ttl': {'N': '1739108034'}, 'cached_result': {'S': '[{\"sentimentanalysis\": {\"positive\": 0.5, \"negative\": 0.3, \"neutral\": 0.2}}, {\"summarization\": {\"summary\": \"The product is well-received, but delivery was delayed.\", \"recommendations\": [\"Improve delivery timelines.\", \"Communicate delivery status proactively to customers.\"]}}]'}, 'cache_key': {'S': '432988856b8ae00e00a51aef60b6f8f79d96266fbaf37a0ca7f62ab62a31d63e'}}\n",
      "Deleting item:  15345\n"
     ]
    }
   ],
   "source": [
    "items =dynamodb.scan(TableName=TABLE_NAME)\n",
    "\n",
    "for item in items[\"Items\"]:\n",
    "    print(\"Deleting item: \", item)\n",
    "    print(\"Deleting item: \", item[\"feedback_id\"][\"S\"])\n",
    "    dynamodb.delete_item(TableName=TABLE_NAME, Key={\n",
    "        \"feedback_id\": {\"S\": str(item[\"feedback_id\"][\"S\"])},\n",
    "        \"cache_key\": {\"S\": str(item[\"cache_key\"][\"S\"])}\n",
    "        }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Items': [],\n",
       " 'Count': 0,\n",
       " 'ScannedCount': 0,\n",
       " 'ResponseMetadata': {'RequestId': 'F5Q24DHA8PSD6K061S0R8N45KBVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'Server',\n",
       "   'date': 'Sun, 09 Feb 2025 17:03:53 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '39',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'F5Q24DHA8PSD6K061S0R8N45KBVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "   'x-amz-crc32': '3413411624'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items =dynamodb.scan(TableName=TABLE_NAME)\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Items': [],\n",
       " 'Count': 0,\n",
       " 'ScannedCount': 0,\n",
       " 'ResponseMetadata': {'RequestId': 'F5Q24DHA8PSD6K061S0R8N45KBVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'Server',\n",
       "   'date': 'Sun, 09 Feb 2025 17:03:53 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '39',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'F5Q24DHA8PSD6K061S0R8N45KBVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "   'x-amz-crc32': '3413411624'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1739108076"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "ttl = int(datetime.now().timestamp())\n",
    "ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Items': [],\n",
       " 'Count': 0,\n",
       " 'ScannedCount': 0,\n",
       " 'ResponseMetadata': {'RequestId': '3M09D1008DA0RG3R630KMSANH3VV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'Server',\n",
       "   'date': 'Sun, 09 Feb 2025 13:48:28 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '39',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '3M09D1008DA0RG3R630KMSANH3VV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "   'x-amz-crc32': '3413411624'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items =dynamodb.scan(TableName=TABLE_NAME)\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1739108382.5497642"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TimeToLiveDescription': {'TimeToLiveStatus': 'DISABLED'},\n",
       " 'ResponseMetadata': {'RequestId': 'DVKACJBNPDU2Q6A1CB9QSJB5EBVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'Server',\n",
       "   'date': 'Sun, 09 Feb 2025 17:04:05 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '57',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'DVKACJBNPDU2Q6A1CB9QSJB5EBVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "   'x-amz-crc32': '243044618'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = dynamodb.describe_time_to_live(TableName=TABLE_NAME)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Enable TTL on an existing DynamoDB table\n",
    "response = dynamodb.update_time_to_live(\n",
    "    TableName=TABLE_NAME,\n",
    "    TimeToLiveSpecification={\n",
    "        'Enabled': True,\n",
    "        'AttributeName': \"ttl\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TimeToLiveSpecification': {'Enabled': True, 'AttributeName': 'ttl'},\n",
       " 'ResponseMetadata': {'RequestId': 'D8I4MR0VHU4SUNS8LJS2UDNHRRVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'Server',\n",
       "   'date': 'Sun, 09 Feb 2025 17:04:08 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '66',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'D8I4MR0VHU4SUNS8LJS2UDNHRRVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "   'x-amz-crc32': '2108816323'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
